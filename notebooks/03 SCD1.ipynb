{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee13555-95ec-475d-83d1-983ebefe6d90",
   "metadata": {},
   "source": [
    "# Slowly Changing Dimensions - Type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540a729-1112-412b-a081-44e4631339d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0715f-b512-4088-90e9-482f855eb77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68521c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "spark = SparkSession.builder.appName('scd1').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811a69a0-bbff-4af8-949c-11a18db1c3f2",
   "metadata": {},
   "source": [
    "## 1. Preperation steps\n",
    "In the following cells we will perform the following steps:\n",
    "1. Read-in our target dataframe\n",
    "2. Save the target dataframe as our 'source' dataframe (initial load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b23925c-a067-432f-b955-35743c4c9778",
   "metadata": {},
   "source": [
    "### Read-in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema\n",
    "schema = T.StructType([\n",
    "    T.StructField('CUSTOMER_ID', T.StringType(), True), \n",
    "    T.StructField('FIRST_NAME', T.StringType(), True), \n",
    "    T.StructField('LAST_NAME', T.StringType(), True),\n",
    "    T.StructField('CITY', T.StringType(), True), \n",
    "    T.StructField('COUNTRY', T.StringType(), True), \n",
    "    T.StructField('PHONE', T.StringType(), True),\n",
    "    T.StructField('EMAIL', T.StringType(), True),\n",
    "])\n",
    "\n",
    "# Read-in dataframe\n",
    "df = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('header', True)\n",
    "    .option('schema', schema)\n",
    "    .csv('scd1_data/source.csv')\n",
    ")\n",
    "\n",
    "# Show dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b1671-70d3-470d-b4b3-c602cdcad986",
   "metadata": {},
   "source": [
    "### Saving dataframe as 'output'\n",
    "PySpark has a particular way of saving parquet, delta, and csv files.\n",
    "Because of this, we need to create a helper function, so that our output is saved as a single csv file.\n",
    "Do not worry to much about understanding this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5a679-9cf5-46df-85d8-1800f62861b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_csv(df: DataFrame, file_path: str):\n",
    "    tmp_folder = file_path + 'tmp'\n",
    "    \n",
    "    # Save DataFrame to a temporary folder\n",
    "    (\n",
    "        df\n",
    "        .coalesce(1)  # Ensure a single partition\n",
    "        .write\n",
    "        .mode('overwrite')\n",
    "        .format('csv')\n",
    "        .option('header', True)\n",
    "        .save(tmp_folder)\n",
    "    )\n",
    "    \n",
    "    # Find the single partition file\n",
    "    for file_name in os.listdir(tmp_folder):\n",
    "        if file_name.endswith('.csv'):\n",
    "            tmp_file_path = os.path.join(tmp_folder, file_name)\n",
    "            break\n",
    "    \n",
    "    # Move and rename the file to the final destination\n",
    "    shutil.move(tmp_file_path, file_path)\n",
    "    \n",
    "    # Remove the temporary folder\n",
    "    shutil.rmtree(tmp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad5cdb1-c1d6-4f74-b800-afe3eda4611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_csv(df=df, file_path='scd1_data/target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76894016-84b7-4d0d-854c-60dd8ecc97cc",
   "metadata": {},
   "source": [
    "## 2. Starting the SCD1 Proces\n",
    "Now, we will begin with the implementation of the Slowly Changing Dimensions type 1. We will be implementing the following steps:\n",
    "1. Change the target dataframe by adding or editing some rows.\n",
    "2. Read-in the target and source dataframe.\n",
    "3. Select the rows in source dataframe that are new.\n",
    "4. Select the rows in source dataframe that have been deleted.\n",
    "5. Select the rows in source dataframe that are updated.\n",
    "6. Insert, update, and/or delete the selected rows in the source dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1275ee-88a1-4bb2-89e2-1feeef75187f",
   "metadata": {},
   "source": [
    "### Step 1: Change the target dataframe by adding or editing some rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed422402-0e1c-49d3-93ab-62ff7e449b84",
   "metadata": {},
   "source": [
    "* Make some alterations to the source data.\n",
    "* You can find this file under notebooks/scd1_data/source.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69caf3a8-89d0-4d98-a02c-4185a8fc1655",
   "metadata": {},
   "source": [
    "### Step 2: Read-in the target and source dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6559d2d3-7ea1-4173-815e-f6d4308b10c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in the source dataframe\n",
    "source_schema = T.StructType([\n",
    "    T.StructField('CUSTOMER_ID', T.StringType(), True), \n",
    "    T.StructField('FIRST_NAME', T.StringType(), True), \n",
    "    T.StructField('LAST_NAME', T.StringType(), True),\n",
    "    T.StructField('CITY', T.StringType(), True), \n",
    "    T.StructField('COUNTRY', T.StringType(), True), \n",
    "    T.StructField('PHONE', T.StringType(), True),\n",
    "    T.StructField('EMAIL', T.StringType(), True),\n",
    "])\n",
    "source_df = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('header', True)\n",
    "    .option('schema', schema)\n",
    "    .csv('scd1_data/source.csv')\n",
    ")\n",
    "\n",
    "# Read-in the target dataframe\n",
    "target_schema = T.StructType([\n",
    "    T.StructField('CUSTOMER_ID', T.StringType(), True), \n",
    "    T.StructField('FIRST_NAME', T.StringType(), True), \n",
    "    T.StructField('LAST_NAME', T.StringType(), True),\n",
    "    T.StructField('CITY', T.StringType(), True), \n",
    "    T.StructField('COUNTRY', T.StringType(), True), \n",
    "    T.StructField('PHONE', T.StringType(), True),\n",
    "    T.StructField('EMAIL', T.StringType(), True),\n",
    "])\n",
    "target_df = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('header', True)\n",
    "    .option('schema', schema)\n",
    "    .csv('scd1_data/target.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb58f5-78ed-4896-81b7-3205a9f0aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66294b22-58ff-424d-8c7e-f9b91e0ff679",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ced99af-d008-484b-bc2a-3140e910fcf1",
   "metadata": {},
   "source": [
    "### Step 3: Select the rows in source dataframe that are new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ea3e5-62c3-40aa-bb5a-7be5bc460292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inserts(source_df: DataFrame, target_df: DataFrame):\n",
    "    # Find rows in source_df that are not present in target_df\n",
    "    ### FILL THIS IN ###\n",
    "    insert_df = 'TODO'\n",
    "    ### FILL THIS IN ###\n",
    "    \n",
    "    return insert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906eb4f9-61b2-4b02-8996-c84d3469ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_df = get_inserts(source_df, target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578535b7-8c51-43c0-be98-2d03813dc25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c21266c-f372-4c4a-a09f-410c3ea5582e",
   "metadata": {},
   "source": [
    "### Step 4: Select the rows in source dataframe that have been deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b69dd-c98f-47f1-a190-e3f6f4a134f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deletes(source_df: DataFrame, target_df: DataFrame):\n",
    "    # Find rows in target_df that are not present in source_df\n",
    "    ### FILL THIS IN ###\n",
    "    delete_df = 'TODO'\n",
    "    ### FILL THIS IN ###\n",
    "    \n",
    "    return delete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f41186-e07a-4fe5-bdcb-1b47f5d6649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_df = get_deletes(source_df, target_df).select(*source_df.columns) # extra select to keep column order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b9286-f9a4-4813-941c-f0cc330c451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac789a5-9803-420a-af1f-0ae4a7fca15b",
   "metadata": {},
   "source": [
    "### Step 5: Select the rows in source dataframe that are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa1c1b-61ae-4b87-8801-afbb676ce61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hash_column(df: DataFrame, columns: list, hash_column_name: str = 'CTC_HASH') -> DataFrame:\n",
    "    # Add a hash column to the DataFrame based on the specified columns.\n",
    "    return df.withColumn(hash_column_name, F.sha2(F.concat_ws('||', *columns), 256))\n",
    "\n",
    "def get_updates(source_df: DataFrame, target_df: DataFrame, ctc_cols: list):\n",
    "    # Add hash columns based on the specified columns\n",
    "    source_df_hash = add_hash_column(source_df, ctc_cols)\n",
    "    target_df_hash = add_hash_column(target_df, ctc_cols)\n",
    "    \n",
    "    # Find corresponding rows between source_df and target_df\n",
    "    ### FILL THIS IN ###\n",
    "    overlap_df = 'TODO'\n",
    "    ### FILL THIS IN ###\n",
    "    \n",
    "    # Apply filter to get rows where hash values are different\n",
    "    update_df = (\n",
    "        overlap_df\n",
    "        .filter(F.col('src.CTC_HASH') != F.col('tgt.CTC_HASH'))\n",
    "        .select('src.*')\n",
    "        .drop('CTC_HASH')\n",
    "    )\n",
    "    \n",
    "    return update_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c2b25-5e2b-47e5-9ec5-8bb9119e0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = ['COSTUMER_ID']\n",
    "ctc_cols = [col for col in source_df.columns if col not in key_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79128b73-eb73-4550-bf36-b8c1e2d5c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_df = get_updates(source_df, target_df, ctc_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ef636-8df2-49a1-a7f3-01cf2fe95f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e019f59-bba7-468e-8a32-9ad35dbcbb7f",
   "metadata": {},
   "source": [
    "### Step 6: Insert, update, and/or delete the selected rows in the source dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1c41d-85f4-4c3d-9c6f-652fb0aca798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the target DataFrame\n",
    "def update_target_df(target_df: DataFrame, insert_df: DataFrame, delete_df: DataFrame, update_df: DataFrame) -> DataFrame:\n",
    "    # Step 1: Delete rows in target_df that are present in delete_df\n",
    "    target_df = target_df.join(delete_df, on='CUSTOMER_ID', how='leftanti')\n",
    "    \n",
    "    # Step 2: Insert new rows from insert_df to target_df\n",
    "    target_df = target_df.union(insert_df)\n",
    "    \n",
    "    # Step 3: Update existing rows in target_df with rows from update_df\n",
    "    target_df = target_df.join(update_df, on='CUSTOMER_ID', how='leftanti')\n",
    "    target_df = target_df.union(update_df)\n",
    "    \n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600a957-f28d-41d1-a971-6d3700f747b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = update_target_df(\n",
    "    target_df=target_df,\n",
    "    insert_df=insert_df,\n",
    "    delete_df=delete_df,\n",
    "    update_df=update_df\n",
    ").select(*[field.name for field in target_schema.fields])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80603395-7bc7-4f70-ab6e-9e54c75e732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11403e79-59b5-4c70-a839-b5fd4ef85bed",
   "metadata": {},
   "source": [
    "#### Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4345e808-7acd-47dc-b6a0-5e1619d7e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_csv(df=target_df, file_path='scd1_data/target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5578b740-1c04-4415-8d7f-616ffd4144c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
