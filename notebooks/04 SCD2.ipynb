{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee13555-95ec-475d-83d1-983ebefe6d90",
   "metadata": {},
   "source": [
    "# Slowly Changing Dimensions - Type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f540a729-1112-412b-a081-44e4631339d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d0715f-b512-4088-90e9-482f855eb77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68521c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "spark = SparkSession.builder.appName('scd2').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811a69a0-bbff-4af8-949c-11a18db1c3f2",
   "metadata": {},
   "source": [
    "## 1. Preperation steps\n",
    "In the following cells we will perform the following steps:\n",
    "1. Read-in our target dataframe\n",
    "2. Add our technical columns to this dataframe\n",
    "3. Save the target dataframe as our 'source' dataframe (initial load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b23925c-a067-432f-b955-35743c4c9778",
   "metadata": {},
   "source": [
    "### Read-in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b5dc588d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+-----------------+--------------------+--------------------+--------------------+\n",
      "|    CUSTOMER_ID|FIRST_NAME|LAST_NAME|             CITY|             COUNTRY|               PHONE|               EMAIL|\n",
      "+---------------+----------+---------+-----------------+--------------------+--------------------+--------------------+\n",
      "|DD37Cf93aecA6Dc|    Sheryl|   Baxter|     East Leonard|               Chile|        229.077.5154|zunigavanessa@smi...|\n",
      "|1Ef7b82A4CAAD10|   Preston|   Lozano|East Jimmychester|            Djibouti|          5153435776|     vmata@colon.com|\n",
      "|5Cef8BFA16c5e3c|     Linda|    Olsen|       Bensonview|  Dominican Republic|001-808-617-6467x...|stanleyblackwell@...|\n",
      "|053d585Ab6b3159|    Joanna|   Bender|   West Priscilla|Slovakia (Slovak ...|001-234-203-0635x...|colinalvarado@mil...|\n",
      "|2d08FB17EE273F4|     Aimee|    Downs|    Chavezborough|Bosnia and Herzeg...| (283)437-3886x88321| louis27@gilbert.com|\n",
      "+---------------+----------+---------+-----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define schema\n",
    "schema = T.StructType([\n",
    "    T.StructField('INDEX', T.IntegerType(), True), \n",
    "    T.StructField('CUSTOMER_ID', T.StringType(), True), \n",
    "    T.StructField('FIRST_NAME', T.StringType(), True), \n",
    "    T.StructField('LAST_NAME', T.StringType(), True), \n",
    "    T.StructField('COMPANY', T.StringType(), True), \n",
    "    T.StructField('CITY', T.StringType(), True), \n",
    "    T.StructField('COUNTRY', T.StringType(), True), \n",
    "    T.StructField('PHONE_1', T.StringType(), True), \n",
    "    T.StructField('PHONE_2', T.StringType(), True), \n",
    "    T.StructField('EMAIL', T.StringType(), True), \n",
    "    T.StructField('SUBSCRIPTION_DATE', T.DateType(), True), \n",
    "    T.StructField('WEBSITE', T.StringType(), True)\n",
    "])\n",
    "\n",
    "# Read-in dataframe\n",
    "df = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('header', True)\n",
    "    .option('schema', schema)\n",
    "    .csv('scd2_data/source.csv')\n",
    ")\n",
    "\n",
    "# Show dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a5868-e518-4774-8620-63df9767bdf0",
   "metadata": {},
   "source": [
    "### Add technical columns\n",
    "We start be defining helper functions to add our technical columns to the dataframe.\n",
    "Here, the following columns are added:\n",
    "* `VALID_FROM`: indicates the timestamp at which this row was valid.\n",
    "* `VALID_TO`: indicates the timestamp at which this row was/is no longer valid.\n",
    "* `isCurrent`: indicates whether this row is currently 'active' or not.\n",
    "\n",
    "This can be done using the `pyspark.sql.types` and `pyspark.sql.function` modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0ba7ced6-60d0-4c8c-b941-b21c92028688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_columns(df: DataFrame, curr_timestamp: datetime = datetime.now()) -> DataFrame:\n",
    "    return (\n",
    "        df\n",
    "        .withColumn('VALID_FROM', F.lit(curr_timestamp).cast(T.TimestampType()))\n",
    "        .withColumn('VALID_TO', F.lit('9999-12-31 23:59:59').cast(T.TimestampType()))\n",
    "        .withColumn('isCurrent', F.lit('Y').cast(T.StringType()))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f7e241da-593c-4826-8abc-789a28044147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_technical_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb1ec885-44c2-482c-9859-05abcbc08e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+-----------------+--------------------+--------------------+--------------------+--------------------+-------------------+---------+\n",
      "|    CUSTOMER_ID|FIRST_NAME|LAST_NAME|             CITY|             COUNTRY|               PHONE|               EMAIL|          VALID_FROM|           VALID_TO|isCurrent|\n",
      "+---------------+----------+---------+-----------------+--------------------+--------------------+--------------------+--------------------+-------------------+---------+\n",
      "|DD37Cf93aecA6Dc|    Sheryl|   Baxter|     East Leonard|               Chile|        229.077.5154|zunigavanessa@smi...|2024-05-15 17:42:...|9999-12-31 23:59:59|        Y|\n",
      "|1Ef7b82A4CAAD10|   Preston|   Lozano|East Jimmychester|            Djibouti|          5153435776|     vmata@colon.com|2024-05-15 17:42:...|9999-12-31 23:59:59|        Y|\n",
      "|5Cef8BFA16c5e3c|     Linda|    Olsen|       Bensonview|  Dominican Republic|001-808-617-6467x...|stanleyblackwell@...|2024-05-15 17:42:...|9999-12-31 23:59:59|        Y|\n",
      "|053d585Ab6b3159|    Joanna|   Bender|   West Priscilla|Slovakia (Slovak ...|001-234-203-0635x...|colinalvarado@mil...|2024-05-15 17:42:...|9999-12-31 23:59:59|        Y|\n",
      "|2d08FB17EE273F4|     Aimee|    Downs|    Chavezborough|Bosnia and Herzeg...| (283)437-3886x88321| louis27@gilbert.com|2024-05-15 17:42:...|9999-12-31 23:59:59|        Y|\n",
      "+---------------+----------+---------+-----------------+--------------------+--------------------+--------------------+--------------------+-------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b1671-70d3-470d-b4b3-c602cdcad986",
   "metadata": {},
   "source": [
    "### Saving dataframe as 'output'\n",
    "PySpark has a particular way of saving parquet, delta, and csv files.\n",
    "Because of this, we need to create a helper function, so that our output is saved as a single csv file.\n",
    "Do not worry to much about understanding this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5dd5a679-9cf5-46df-85d8-1800f62861b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_csv(df: DataFrame, file_path: str):\n",
    "    tmp_folder = file_path + 'tmp'\n",
    "    \n",
    "    # Save DataFrame to a temporary folder\n",
    "    (\n",
    "        df\n",
    "        .coalesce(1)  # Ensure a single partition\n",
    "        .write\n",
    "        .mode('overwrite')\n",
    "        .format('csv')\n",
    "        .option('header', True)\n",
    "        .save(tmp_folder)\n",
    "    )\n",
    "    \n",
    "    # Find the single partition file\n",
    "    for file_name in os.listdir(tmp_folder):\n",
    "        if file_name.endswith('.csv'):\n",
    "            tmp_file_path = os.path.join(tmp_folder, file_name)\n",
    "            break\n",
    "    \n",
    "    # Move and rename the file to the final destination\n",
    "    shutil.move(tmp_file_path, file_path)\n",
    "    \n",
    "    # Remove the temporary folder\n",
    "    shutil.rmtree(tmp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fad5cdb1-c1d6-4f74-b800-afe3eda4611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_csv(df=df, file_path='scd2_data/target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76894016-84b7-4d0d-854c-60dd8ecc97cc",
   "metadata": {},
   "source": [
    "## 2. Starting the SCD2 Proces\n",
    "Now, we will begin with the implementation of the Slowly Changing Dimensions type 1. We will be implementing the following steps:\n",
    "1. Change the target dataframe by adding or editing some rows.\n",
    "2. Read-in the target and source dataframe.\n",
    "3. Select the rows in source dataframe that are new.\n",
    "4. Select the rows in source dataframe that have been deleted.\n",
    "5. Select the rows in source dataframe that are updated.\n",
    "6. Insert, update, and/or delete the selected rows in the source dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1275ee-88a1-4bb2-89e2-1feeef75187f",
   "metadata": {},
   "source": [
    "### Step 1: Change the target dataframe by adding or editing some rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed422402-0e1c-49d3-93ab-62ff7e449b84",
   "metadata": {},
   "source": [
    "* Make some alterations to the source data.\n",
    "* You can find this file under notebooks/scd2_data/source.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69caf3a8-89d0-4d98-a02c-4185a8fc1655",
   "metadata": {},
   "source": [
    "### Step 2: Read-in the target and source dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6559d2d3-7ea1-4173-815e-f6d4308b10c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in the source dataframe\n",
    "source_schema = T.StructType([\n",
    "    T.StructField('INDEX', T.IntegerType(), True), \n",
    "    T.StructField('CUSTOMER_ID', T.StringType(), True), \n",
    "    T.StructField('FIRST_NAME', T.StringType(), True), \n",
    "    T.StructField('LAST_NAME', T.StringType(), True), \n",
    "    T.StructField('COMPANY', T.StringType(), True), \n",
    "    T.StructField('CITY', T.StringType(), True), \n",
    "    T.StructField('COUNTRY', T.StringType(), True), \n",
    "    T.StructField('PHONE_1', T.StringType(), True), \n",
    "    T.StructField('PHONE_2', T.StringType(), True), \n",
    "    T.StructField('EMAIL', T.StringType(), True), \n",
    "    T.StructField('SUBSCRIPTION_DATE', T.DateType(), True), \n",
    "    T.StructField('WEBSITE', T.StringType(), True)\n",
    "])\n",
    "source_df = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('header', True)\n",
    "    .option('schema', schema)\n",
    "    .csv('scd2_data/source.csv')\n",
    ")\n",
    "\n",
    "# Read-in the target dataframe\n",
    "target_schema = T.StructType([\n",
    "    T.StructField('INDEX', T.IntegerType(), True), \n",
    "    T.StructField('CUSTOMER_ID', T.StringType(), True), \n",
    "    T.StructField('FIRST_NAME', T.StringType(), True), \n",
    "    T.StructField('LAST_NAME', T.StringType(), True), \n",
    "    T.StructField('COMPANY', T.StringType(), True), \n",
    "    T.StructField('CITY', T.StringType(), True), \n",
    "    T.StructField('COUNTRY', T.StringType(), True), \n",
    "    T.StructField('PHONE_1', T.StringType(), True), \n",
    "    T.StructField('PHONE_2', T.StringType(), True), \n",
    "    T.StructField('EMAIL', T.StringType(), True), \n",
    "    T.StructField('SUBSCRIPTION_DATE', T.DateType(), True), \n",
    "    T.StructField('WEBSITE', T.StringType(), True),\n",
    "    T.StructField('VALID_FROM', T.TimestampType(), True),\n",
    "    T.StructField('VALID_TO', T.TimestampType(), True),\n",
    "    T.StructField('isCurrent', T.StringType(), True),\n",
    "])\n",
    "target_df = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('header', True)\n",
    "    .option('schema', schema)\n",
    "    .csv('scd2_data/target.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "afcb58f5-78ed-4896-81b7-3205a9f0aa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+-----------------+--------------------+--------------------+--------------------+\n",
      "|    CUSTOMER_ID|FIRST_NAME|LAST_NAME|             CITY|             COUNTRY|               PHONE|               EMAIL|\n",
      "+---------------+----------+---------+-----------------+--------------------+--------------------+--------------------+\n",
      "|1Ef7b82A4CAAD10|  Prestoni|  Lozanoi|East Jimmychester|            Djibouti|          5153435776|     vmata@colon.com|\n",
      "|XXXXXXXXXXXXXXX|     Puppi| Schtinki|East Jimmychester|            Djibouti|          5153435776|     vmata@colon.com|\n",
      "|5Cef8BFA16c5e3c|     Linda|    Olsen|       Bensonview|  Dominican Republic|001-808-617-6467x...|stanleyblackwell@...|\n",
      "|053d585Ab6b3159|    Joanna|   Bender|   West Priscilla|Slovakia (Slovak ...|001-234-203-0635x...|colinalvarado@mil...|\n",
      "|2d08FB17EE273F4|     Aimee|    Downs|    Chavezborough|Bosnia and Herzeg...| (283)437-3886x88321| louis27@gilbert.com|\n",
      "+---------------+----------+---------+-----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "66294b22-58ff-424d-8c7e-f9b91e0ff679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|    CUSTOMER_ID|FIRST_NAME|LAST_NAME|             CITY|             COUNTRY|               PHONE|               EMAIL|          VALID_FROM|            VALID_TO|isCurrent|\n",
      "+---------------+----------+---------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|DD37Cf93aecA6Dc|    Sheryl|   Baxter|     East Leonard|               Chile|        229.077.5154|zunigavanessa@smi...|2024-05-15T17:42:...|9999-12-31T23:59:...|        Y|\n",
      "|1Ef7b82A4CAAD10|   Preston|   Lozano|East Jimmychester|            Djibouti|          5153435776|     vmata@colon.com|2024-05-15T17:42:...|9999-12-31T23:59:...|        Y|\n",
      "|5Cef8BFA16c5e3c|     Linda|    Olsen|       Bensonview|  Dominican Republic|001-808-617-6467x...|stanleyblackwell@...|2024-05-15T17:42:...|9999-12-31T23:59:...|        Y|\n",
      "|053d585Ab6b3159|    Joanna|   Bender|   West Priscilla|Slovakia (Slovak ...|001-234-203-0635x...|colinalvarado@mil...|2024-05-15T17:42:...|9999-12-31T23:59:...|        Y|\n",
      "|2d08FB17EE273F4|     Aimee|    Downs|    Chavezborough|Bosnia and Herzeg...| (283)437-3886x88321| louis27@gilbert.com|2024-05-15T17:42:...|9999-12-31T23:59:...|        Y|\n",
      "+---------------+----------+---------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ced99af-d008-484b-bc2a-3140e910fcf1",
   "metadata": {},
   "source": [
    "### Step 3: Select the rows in source dataframe that are new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "647ea3e5-62c3-40aa-bb5a-7be5bc460292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inserts(source_df: DataFrame, target_df: DataFrame):\n",
    "    # Find rows in source_df that are not present in target_df\n",
    "    insert_df = source_df.join(target_df, on='CUSTOMER_ID', how='leftanti')\n",
    "    \n",
    "    return insert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "906eb4f9-61b2-4b02-8996-c84d3469ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_df = get_inserts(source_df, target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "578535b7-8c51-43c0-be98-2d03813dc25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+-----------------+--------+----------+---------------+\n",
      "|    CUSTOMER_ID|FIRST_NAME|LAST_NAME|             CITY| COUNTRY|     PHONE|          EMAIL|\n",
      "+---------------+----------+---------+-----------------+--------+----------+---------------+\n",
      "|XXXXXXXXXXXXXXX|     Puppi| Schtinki|East Jimmychester|Djibouti|5153435776|vmata@colon.com|\n",
      "+---------------+----------+---------+-----------------+--------+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c21266c-f372-4c4a-a09f-410c3ea5582e",
   "metadata": {},
   "source": [
    "### Step 4: Select the rows in source dataframe that have been deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "508b69dd-c98f-47f1-a190-e3f6f4a134f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deletes(source_df: DataFrame, target_df: DataFrame):\n",
    "    # Find rows in target_df that are not present in source_df\n",
    "    delete_df = target_df.join(source_df, on='CUSTOMER_ID', how='leftanti')\n",
    "    \n",
    "    return delete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "20f41186-e07a-4fe5-bdcb-1b47f5d6649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_df = get_deletes(source_df, target_df).select(*source_df.columns) # extra select to keep column order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e74b9286-f9a4-4813-941c-f0cc330c451a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+------------+-------+------------+--------------------+\n",
      "|    CUSTOMER_ID|FIRST_NAME|LAST_NAME|        CITY|COUNTRY|       PHONE|               EMAIL|\n",
      "+---------------+----------+---------+------------+-------+------------+--------------------+\n",
      "|DD37Cf93aecA6Dc|    Sheryl|   Baxter|East Leonard|  Chile|229.077.5154|zunigavanessa@smi...|\n",
      "+---------------+----------+---------+------------+-------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delete_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac789a5-9803-420a-af1f-0ae4a7fca15b",
   "metadata": {},
   "source": [
    "### Step 5: Select the rows in source dataframe that are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a1fa1c1b-61ae-4b87-8801-afbb676ce61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hash_column(df: DataFrame, columns: list, hash_column_name: str = 'CTC_HASH') -> DataFrame:\n",
    "    # Add a hash column to the DataFrame based on the specified columns.\n",
    "    return df.withColumn(hash_column_name, F.sha2(F.concat_ws('||', *columns), 256))\n",
    "\n",
    "def get_updates(source_df: DataFrame, target_df: DataFrame, ctc_cols: list):\n",
    "    # Add hash columns based on the specified columns\n",
    "    source_df_hash = add_hash_column(source_df, ctc_cols)\n",
    "    target_df_hash = add_hash_column(target_df, ctc_cols)\n",
    "    \n",
    "    # Find corresponding rows between source_df and target_df\n",
    "    overlap_df = source_df_hash.alias('src').join(target_df_hash.alias('tgt'), on='CUSTOMER_ID', how='inner')\n",
    "    \n",
    "    # Apply filter to get rows where hash values are different\n",
    "    update_df = (\n",
    "        overlap_df\n",
    "        .filter(F.col('src.CTC_HASH') != F.col('tgt.CTC_HASH'))\n",
    "        .select('src.*')\n",
    "        .drop('CTC_HASH')\n",
    "    )\n",
    "    \n",
    "    return update_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2e8c2b25-5e2b-47e5-9ec5-8bb9119e0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = ['COSTUMER_ID']\n",
    "ctc_cols = [col for col in source_df.columns if col not in key_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "79128b73-eb73-4550-bf36-b8c1e2d5c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_df = get_updates(source_df, target_df, ctc_cols).select(*source_df.columns) # extra select to keep column order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c82ef636-8df2-49a1-a7f3-01cf2fe95f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+-----------------+--------+----------+---------------+\n",
      "|    CUSTOMER_ID|FIRST_NAME|LAST_NAME|             CITY| COUNTRY|     PHONE|          EMAIL|\n",
      "+---------------+----------+---------+-----------------+--------+----------+---------------+\n",
      "|1Ef7b82A4CAAD10|  Prestoni|  Lozanoi|East Jimmychester|Djibouti|5153435776|vmata@colon.com|\n",
      "+---------------+----------+---------+-----------------+--------+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "update_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e019f59-bba7-468e-8a32-9ad35dbcbb7f",
   "metadata": {},
   "source": [
    "### Step 6: Insert, update, and/or delete the selected rows in the source dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "21b1dd8f-0384-4197-b09a-995203a7acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_timestamp = datetime.now() # we need this for our inserts, updates and deletes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe64c04-bd53-46d2-a321-c9710876490a",
   "metadata": {},
   "source": [
    "#### Handling deletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "91f22ec9-9cdf-44d1-ada9-631a78f8f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_deletes(target_df: DataFrame, delete_df: DataFrame, curr_timestamp: datetime):\n",
    "    # Step 1: Find the rows with the same key in the target_df\n",
    "    records_to_invalidate = (\n",
    "        target_df.alias('tgt')\n",
    "        .join(delete_df.alias('inv'), on='CUSTOMER_ID', how='inner')\n",
    "        .select('tgt.*')\n",
    "    )\n",
    "    \n",
    "    # Step 2: Create new dataframe with updated VALID_TO and isCurrent = 'N'\n",
    "    invalidated_records = (\n",
    "        records_to_invalidate\n",
    "        .withColumn(\"VALID_TO\", F.lit(curr_timestamp).cast(T.TimestampType()))\n",
    "        .withColumn(\"isCurrent\", F.lit(\"N\").cast(T.StringType()))\n",
    "    )\n",
    "\n",
    "    # Step 3: Delete current active records from the dataframe\n",
    "    target_df = target_df.join(invalidated_records, on='CUSTOMER_ID', how='leftanti')\n",
    "    \n",
    "    # Step 4: Add new invalidated records to target_df\n",
    "    target_df = target_df.union(invalidated_records)\n",
    "\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c6afa4bb-606d-4d46-bf5f-c5eed604f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = handle_deletes(target_df, delete_df, curr_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "771f2c8a-f35d-4a98-84a6-bb3aecc3eb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+---------------+---------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|    CUSTOMER_ID|FIRST_NAME|LAST_NAME|           CITY|        COUNTRY|               PHONE|               EMAIL|          VALID_FROM|            VALID_TO|isCurrent|\n",
      "+---------------+----------+---------+---------------+---------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|CeD220bdAaCfaDf|      Lynn| Atkinson|   New Bradview|      Sri Lanka|     +1-846-706-2218|   vkemp@ferrell.com|2024-05-15T17:42:...|9999-12-31T23:59:...|        Y|\n",
      "|28CDbC0dFe4b1Db|      Fred|   Guerra|     Ortegaland|Solomon Islands|+1-753-067-8419x7170|    swagner@kane.org|2024-05-15T17:42:...|9999-12-31T23:59:...|        Y|\n",
      "|c23d1D9EE8DEB0A|    Yvonne|   Farmer|Lake Elijahview|          Aruba|       (530)311-9786|mccarthystephen@h...|2024-05-15T17:42:...|9999-12-31T23:59:...|        Y|\n",
      "|2354a0E336A91A1|  Clarence|   Haynes|      Judymouth|       Honduras|       (753)813-6941|colleen91@faulkne...|2024-05-15T17:42:...|9999-12-31T23:59:...|        Y|\n",
      "|DD37Cf93aecA6Dc|    Sheryl|   Baxter|   East Leonard|          Chile|        229.077.5154|zunigavanessa@smi...|2024-05-15T17:42:...|2024-05-15 17:52:...|        N|\n",
      "+---------------+----------+---------+---------------+---------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the last 5 rows of the dataframe\n",
    "last_five_df = spark.createDataFrame(target_df.tail(5), target_df.schema)\n",
    "last_five_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd64f3-f187-4954-9c9b-dc8648648229",
   "metadata": {},
   "source": [
    "#### Handling updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "91a1c41d-85f4-4c3d-9c6f-652fb0aca798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the target DataFrame\n",
    "def handle_updates(target_df: DataFrame, update_df: DataFrame, curr_timestamp: datetime) -> DataFrame:\n",
    "    # Step 1: Invalidate existing rows in target_df with rows from update_df (hint: use handle_deletes())\n",
    "    target_df = handle_deletes(target_df, update_df, curr_timestamp)\n",
    "\n",
    "    # Step 2: Add technical columns to update_df (hint: use add_technical_columns())\n",
    "    update_df = add_technical_columns(update_df, curr_timestamp)\n",
    "    \n",
    "    # Step 3: Insert new rows from update_df to target_df\n",
    "    target_df = target_df.union(update_df)\n",
    "\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "aa74d187-113b-4fbb-97a5-c19837dd225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = handle_updates(target_df, update_df, curr_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f859fb18-95df-4cbd-8b29-452b564c8fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+-----------------+-------------+------------+--------------------+--------------------+--------------------+---------+\n",
      "|    CUSTOMER_ID|FIRST_NAME|LAST_NAME|             CITY|      COUNTRY|       PHONE|               EMAIL|          VALID_FROM|            VALID_TO|isCurrent|\n",
      "+---------------+----------+---------+-----------------+-------------+------------+--------------------+--------------------+--------------------+---------+\n",
      "|7Ce381e4Afa4ba9|   Gabriel|    Mejia|    Port Annatown|Liechtenstein|  4077245425|coleolson@jenning...|2024-05-15T17:42:...|9999-12-31T23:59:...|        Y|\n",
      "|DD37Cf93aecA6Dc|    Sheryl|   Baxter|     East Leonard|        Chile|229.077.5154|zunigavanessa@smi...|2024-05-15T17:42:...|2024-05-15 17:52:...|        N|\n",
      "|1Ef7b82A4CAAD10|   Preston|   Lozano|East Jimmychester|     Djibouti|  5153435776|     vmata@colon.com|2024-05-15T17:42:...|2024-05-15 17:52:...|        N|\n",
      "|1Ef7b82A4CAAD10|  Prestoni|  Lozanoi|East Jimmychester|     Djibouti|  5153435776|     vmata@colon.com|2024-05-15 17:52:...|2024-05-15 17:52:...|        N|\n",
      "|1Ef7b82A4CAAD10|  Prestoni|  Lozanoi|East Jimmychester|     Djibouti|  5153435776|     vmata@colon.com|2024-05-15 17:52:...| 9999-12-31 23:59:59|        Y|\n",
      "+---------------+----------+---------+-----------------+-------------+------------+--------------------+--------------------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the last 5 rows of the dataframe\n",
    "last_five_df = spark.createDataFrame(target_df.tail(5), target_df.schema)\n",
    "last_five_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5bb693-ca92-4314-b291-51dbfdcd940f",
   "metadata": {},
   "source": [
    "#### Handling inserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bb8cc2ef-4e88-46fa-8125-5b6dafc4da58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_inserts(target_df: DataFrame, insert_df: DataFrame, curr_timestamp: datetime):\n",
    "    # Step 1: Add technical columns to update_df (hint: use add_technical_columns())\n",
    "    update_df = add_technical_columns(insert_df, curr_timestamp)\n",
    "    \n",
    "    # Step 2: insert rows from insert_df into target_df\n",
    "    target_df = target_df.union(insert_df)\n",
    "    \n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a600a957-f28d-41d1-a971-6d3700f747b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = handle_updates(target_df, insert_df, curr_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "80603395-7bc7-4f70-ab6e-9e54c75e732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+-----------------+--------+------------+--------------------+--------------------+--------------------+---------+\n",
      "|    CUSTOMER_ID|FIRST_NAME|LAST_NAME|             CITY| COUNTRY|       PHONE|               EMAIL|          VALID_FROM|            VALID_TO|isCurrent|\n",
      "+---------------+----------+---------+-----------------+--------+------------+--------------------+--------------------+--------------------+---------+\n",
      "|DD37Cf93aecA6Dc|    Sheryl|   Baxter|     East Leonard|   Chile|229.077.5154|zunigavanessa@smi...|2024-05-15T17:42:...|2024-05-15 17:52:...|        N|\n",
      "|1Ef7b82A4CAAD10|   Preston|   Lozano|East Jimmychester|Djibouti|  5153435776|     vmata@colon.com|2024-05-15T17:42:...|2024-05-15 17:52:...|        N|\n",
      "|1Ef7b82A4CAAD10|  Prestoni|  Lozanoi|East Jimmychester|Djibouti|  5153435776|     vmata@colon.com|2024-05-15 17:52:...|2024-05-15 17:52:...|        N|\n",
      "|1Ef7b82A4CAAD10|  Prestoni|  Lozanoi|East Jimmychester|Djibouti|  5153435776|     vmata@colon.com|2024-05-15 17:52:...| 9999-12-31 23:59:59|        Y|\n",
      "|XXXXXXXXXXXXXXX|     Puppi| Schtinki|East Jimmychester|Djibouti|  5153435776|     vmata@colon.com|2024-05-15 17:52:...| 9999-12-31 23:59:59|        Y|\n",
      "+---------------+----------+---------+-----------------+--------+------------+--------------------+--------------------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the last 5 rows of the dataframe\n",
    "last_five_df = spark.createDataFrame(target_df.tail(5), target_df.schema)\n",
    "last_five_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d7c94f-1248-4bf1-974e-61d8d686f15d",
   "metadata": {},
   "source": [
    "#### Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4345e808-7acd-47dc-b6a0-5e1619d7e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_csv(df=target_df, file_path='scd2_data/target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a6b615-01d2-43fa-95b3-cd94748f1d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
